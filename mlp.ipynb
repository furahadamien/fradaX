{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/furahadamien/fradaX/blob/master/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4PiBFH3Fqwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "2b45b620-466a-4f5b-ba5b-2875be8d907a"
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np ## For numerical python\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "from IPython.display import clear_output\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "np.random.seed(42)\n",
        "\n",
        "#class to allow for forward pass and back pass\n",
        "class Layer:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def forward(self, input):\n",
        "    return input\n",
        "  \n",
        "  def backward(self, input, grad_output):\n",
        "    num_units = input.shape[1]\n",
        "        \n",
        "    d_layer_d_input = np.eye(num_units)\n",
        "        \n",
        "    return np.dot(grad_output, d_layer_d_input)\n",
        "\n",
        "#Non-Linearlity activation function\n",
        "class ReLU(Layer):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def forward(self, input):\n",
        "    relu_forward = np.maximum(0,input)\n",
        "    return relu_forward\n",
        "  \n",
        "  def backward(self, input, grad_output):\n",
        "    relu_grad = input > 0\n",
        "    return grad_output*relu_grad\n",
        "\n",
        "class Dense(Layer):\n",
        "  def __init__(self, input_units, output_units, learning_rate=0.1):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weights = np.random.normal(loc=0.0, \n",
        "      scale = np.sqrt(2/(input_units+output_units)), \n",
        "      size = (input_units,output_units))\n",
        "    self.biases = np.zeros(output_units)\n",
        "  \n",
        "  def forward(self,input):\n",
        "    return np.dot(input,self.weights) + self.biases\n",
        "  \n",
        "  def backward(self,input,grad_output):\n",
        "    grad_input = np.dot(grad_output, self.weights.T)\n",
        "    grad_weights = np.dot(input.T, grad_output)\n",
        "    grad_biases = grad_output.mean(axis=0)*input.shape[0]\n",
        "    assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
        "\n",
        "    #Stochastic Gradient Descent\n",
        "    self.weights = self.weights - self.learning_rate * grad_weights\n",
        "    self.biases = self.biases - self.learning_rate * grad_biases\n",
        "    return grad_input\n",
        "\n",
        "def softmax_crossentropy_with_logits(logits,reference_answers):\n",
        "  logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
        "  xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
        "  return xentropy\n",
        "\n",
        "def grad_softmax_crossentropy_with_logits(logits,reference_answers):\n",
        "  ones_for_answers = np.zeros_like(logits)\n",
        "  ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
        "  softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
        "  return (- ones_for_answers + softmax) / logits.shape[0]\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "#loading dataset\n",
        "def load_dataset(flatten=False):\n",
        "    (X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "\n",
        "    # normalize x\n",
        "    X_train = X_train.astype(float) / 255.\n",
        "    X_test = X_test.astype(float) / 255.\n",
        "\n",
        "    # we reserve the last 10000 training examples for validation\n",
        "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
        "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
        "\n",
        "    if flatten:\n",
        "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
        "        X_val = X_val.reshape([X_val.shape[0], -1])\n",
        "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(flatten=True)\n",
        "## Let's look at some example\n",
        "\n",
        "\"\"\"\n",
        "plt.figure(figsize=[6,6])\n",
        "X_train = X_train.reshape(10000,3072)\n",
        "fig, axes1 = plt.subplots(5,5,figsize=(3,3))\n",
        "for j in range(5):\n",
        "    for k in range(5):\n",
        "        i = np.random.choice(range(len(X_train)))\n",
        "        axes1[j][k].set_axis_off()\n",
        "        axes1[j][k].imshow(X_train[i:i+1][0])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(X_train, \n",
        "    batch_size=4, shuffle=True, num_workers=2)\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\"\"\"\n",
        "#defining a network as a list of layers\n",
        "network = []\n",
        "network.append(Dense(X_train.shape[1],100))\n",
        "network.append(ReLU())\n",
        "network.append(Dense(100,200))\n",
        "network.append(ReLU())\n",
        "network.append(Dense(200,10))\n",
        "\n",
        "def forward(network, X):\n",
        "  #print(\"lenths\")\n",
        "  #print(len(X))\n",
        "  activations = []\n",
        "  input = X\n",
        "\n",
        "  for l in network:\n",
        "    activations.append(l.forward(input))\n",
        "    input = activations[-1]\n",
        "    #print(\"lengths are : \")\n",
        "    #print(len(activations))\n",
        "    #print(len(network))\n",
        "  assert len(activations) == len(network)\n",
        "  return activations\n",
        "\n",
        "def predict(network,X):\n",
        "  logits = forward(network,X)[-1]\n",
        "  return logits.argmax(axis=-1)\n",
        "\n",
        "def train(network,X,y):\n",
        "  layer_activations = forward(network,X)\n",
        "  layer_inputs = [X]+layer_activations \n",
        "  logits = layer_activations[-1]\n",
        "\n",
        "  loss = softmax_crossentropy_with_logits(logits,y)\n",
        "  loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
        "\n",
        "  for layer_index in range(len(network))[::-1]:\n",
        "    layer = network[layer_index]\n",
        "    loss_grad = layer.backward(layer_inputs[layer_index],loss_grad)\n",
        "\n",
        "  return np.mean(loss)\n",
        "\n",
        "#Training the network\n",
        "#we are using the mini-batch stochastic grandient descent method\n",
        "#we split data in to mini-batches and feed them into the network while updating weights\n",
        "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
        "  assert len(inputs) == len(targets)\n",
        "  if shuffle:\n",
        "    indices = np.random.permutation(len(inputs))\n",
        "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
        "      if shuffle:\n",
        "        excerpt = indices[start_idx:start_idx + batchsize]\n",
        "      else:\n",
        "        excerpt = slice(start_idx, start_idx + batchsize)\n",
        "      yield inputs[excerpt], targets[excerpt]\n",
        "train_log = []\n",
        "val_log = []\n",
        "\n",
        "for epoch in range(25):\n",
        "\n",
        "    for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=32,shuffle=True):\n",
        "        train(network,x_batch,y_batch)\n",
        "    \n",
        "    train_log.append(np.mean(predict(network,X_train)==y_train))\n",
        "    val_log.append(np.mean(predict(network,X_val)==y_val))\n",
        "    \n",
        "    clear_output()\n",
        "    print(\"Epoch\",epoch)\n",
        "    print(\"Train accuracy:\",train_log[-1])\n",
        "    print(\"Val accuracy:\",val_log[-1])\n",
        "    plt.plot(train_log,label='train accuracy')\n",
        "    plt.plot(val_log,label='val accuracy')\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 4\n",
            "Train accuracy: 0.09965\n",
            "Val accuracy: 0.1014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 188/1250 [00:01<00:07, 149.09it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}